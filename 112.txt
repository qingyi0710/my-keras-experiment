from keras.datasets import cifar10
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.optimizers import SGD, Adam, RMSprop
from keras import backend as K

# CIFAR-10 contains 60 000 32*32*3 images
IMG_CHANNELS = 3
IMG_ROWS = 32
IMG_COLS = 32

# constant
BATCH_SIZE = 128
NB_EPOCH = 20
NB_CLASSES = 10
VERBOSE = 1
VALIDATION_SPLIT = 0.2
OPTIM = RMSprop()

# loading datasets
(X_train,y_train), (X_test, y_test) = cifar10.load_data()
K.set_image_dim_ordering('tf')

# 现在我们来做one-hot编码，并把图像归一化
# classifier changing
y_train = np_utils.to_categorical(y_train, NB_CLASSES)
y_test = np_utils.to_categorical(y_test, NB_CLASSES)

# 将其看成float类型并归一化
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255


#  用深度学习网络改进cifar-10 性能
model = Sequential()
model.add(Conv2D(32, (3, 3), padding='same', input_shape=(IMG_CHANNELS, IMG_ROWS, IMG_COLS)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(NB_CLASSES))
model.add(Activation('softmax'))
model.summary()

model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy'])
model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, validation_data=VALIDATION_SPLIT, verbose=VERBOSE)
# 历史数据的保持，重要
# history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)

score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)

print("Test score:", score[0])
print('Test accuracy:', score[1])


# 保存模型
model_json = model.to_json()
open('cifar10_architecture.json', 'w').write(model_json)
#  and the weights learned bu our deep network on the training set
model.save_weights('cifar10_weights.h5', overwrite=True)



# page 64

model = Sequential()
model.add(Conv2D(32, (3, 3), padding='same', input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))
model.add(Activation('relu'))
model.add(Conv2D(32, (3, 3), padding='same'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

model = Sequential()
model.add(Conv2D(64, (3, 3), padding='same', input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))
model.add(Activation('relu'))
model.add(Conv2D(64, (3, 3), padding='same'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(NB_CLASSES))
model.add(Activation('softmax'))


# 通过数据增加改善CIFAR-10性能
from keras.preprocessing.image import ImageDataGenerator
from keras.datasets import cifar10
import numpy as np

NUM_TO_AUGMENT = 5

# 加载数据集
(X_train, y_train), (X_test, y_test) = cifar10.load_data()

# 拓展
print('augmenting training set images')
datagen = ImageDataGenerator(rotation_range=40,
                             width_shift_range=0.2,
                             height_shift_range=0.2,
                             zoom_range=0.2,  # 随机缩放图片的变化值
                             horizontal_flip=True,  # 进行随机的水平翻转
                             fill_mode='nearest')
xtas, ytas = [], []
for i in range(X_train.shape[0]):
    num_aug = 0
    x = X_train[i]  # (3,32,32)
    x = x.reshape((1, ) + x.shape)  # (1, 3, 32, 32)
    for x_aug in datagen.flow(x, batch_size=1,save_to_dir='preview',
                              save_prefix='cifar', save_format='jpeg'):
        if num_aug >= NUM_TO_AUGMENT:
            break
        xtas.append(x_aug[0])
        num_aug += 1

# 匹配数据
datagen.fit(X_train)

# 训练
history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),
                              samples_per_epoch=X_train.shape[0],
                              epochs=NB_EPOCH, verbose=VERBOSE)

score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)

print("Test score:", score[0])
print('Test accuracy:', score[1])




"""
3,3,3 用cifar-10 进行预测
"""

import numpy as np
import scipy.misc
from keras.models import model_from_json
from keras.optimizers import SGD

# 加载模型
model_architecture = 'cifar_architecture.json'
model_weights = 'cifar10_weights.h5'
model = model_from_json(open(model_architecture).read())
model.load_weights(model_weights)

# 加载图片
img_names = ['cat-standing.jpg', 'dog.jpg']
imgs = [np.transpose(scipy.misc.imresize(scipy.misc.imread(img_name), (32, 32)), (1, 0, 2)).satype(float) for img_name in img_names]
imgs = np.array(imgs) / 255

# 训练
optim = SGD()
model.compile(loss='categorical_crossentropy', optimizer = optim, metrics=['accuracy'])

predictions = model.predict_classes(imgs)
print(predictions)



"""
3.4.2 使用Keras内置的VGG16 网络模块

"""

from keras.models import Model
from keras.preprocessing import image
from keras.optimizers import SGD
from keras.applications.vgg16 import VGG16
import matplotlib.pyplot as plt
import numpy as np
import cv2

# 使用预期训练好的权重在imgaenet上预构建模型
model = VGG16(weights='imagenet', include_top=True)
sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(optimizer=sgd, loss='categorical_crossentropy')


# 图片调整为VGG16训练格式
im = cv2.resize(cv2.imread('steam-locomotive.jpg'), (224, 224))
im = np.expand_dims(im, axis=0)

# prediction
out = model.predict(im)
plt.plot(out.ravel())
plt.show()
print(np.argmax(out))



"""

3.4.3 为特征提取回收内置深度学习模型
"""

from keras.applications.vgg16 import VGG16
from keras.models import Model
from keras.preprocessing import image
from keras.applications.vgg16 import preprocess_input
import numpy as np


# 预置并训练好的VGG16深度学习模型
base_model = VGG16(weights='imagenet', include_top=True)
for i, layer in enumerate(base_model.layers):
    print(i, layer.name, layer.output_shape)

#  从block4_pool块提取特征
model = Model(input=base_model.input, output=base_model.get_layer('block4_pool').output)

img_path = 'cat.jpg'
img = image.load_img(img_path, target_size=(224, 224))

x = img.img_to_array()
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

#  特征提取
features = model.predict(x)



"""
3.4.4 用于迁移学习的极深inception-v3网络
"""


from keras.applications.inception_v3 import InceptionV3
from keras.preprocessing import image
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D
from keras import backend as K

#  创建预训练模型
base_model = InceptionV3(weights='imagenet', include_top=True)

#  layer.name, layer.input_shape, layer.output_shape

#  填加全局空间平均池化层
x = base_model.output
x = GlobalAveragePooling2D()(x)  # let's add a fully connected  layer as first layer
x = Dense(1024, activation='relu')(x)  #  and a logistic layer with 200 classes as last layer
predictions = Dense(200, activation='softmax')(x)  #ｍodel to train
model = Model(input=base_model.input, output=predictions)

#  冻结所有的卷积InceptionV3层
for layer in base_model.layers:
    layer.trainable = False

# 编译模型（应将网络设置为nontrainable之后进行）
model.compile(optimizer='rmsprop', loss='categorical_crossentropy')

# 将模型在新数据上训练几轮
model.fit_generator(..)

# 我们选择训练最上面的两个inception块儿，即我们将冻结前面的172层并解冻其余层
for layer in model.layers[:172]:
    layer.trainable = False
for layer in model.layers[172:]:
    layer.trainable = True

# 我们使用sgd优化器，学习率设置为很小的值
from keras.optimizers import SGD
model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')

#  我们再次训练模型（这次调整最上面的两块儿）
# 最上面是全连接层
model.fit_generator(..)


